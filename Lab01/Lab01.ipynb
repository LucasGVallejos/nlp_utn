{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa6dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98b256",
   "metadata": {},
   "source": [
    "<h1> Using NLTK </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c80fc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8006fd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk.book as books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce1c68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Moby', 'Dick', 'by', 'Herman']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.text1.tokens[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b76b704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre', 'Vinken', ',', '61', 'years']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.text7.tokens[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bac0206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.text1.count(\"Moby\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f5cc4c",
   "metadata": {},
   "source": [
    "<h1> Strings and Regular Expressions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed3000b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8066de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sent = \"The cat sat on the mat.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36568c06",
   "metadata": {},
   "source": [
    "<h4> Tokenizers divide strings into lists of substrings. For example, tokenizers can be used to find the words and punctuation in a string </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8552ce94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'cat', 'sat', 'on', 'the', 'mat', '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(my_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97179440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_tokenize(my_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187df3a3",
   "metadata": {},
   "source": [
    "<h6> Future Reference: https://www.nltk.org/api/nltk.tokenize.html </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ebd0c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95cd7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = re.search(\"leng\", \"procesamiento del lenguaje natural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9778b063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(18, 22), match='leng'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "021bb27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2075731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b11fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = re.search(\"procesan\", \"procesamiento del lenguaje natural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9ab3fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b60f7448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'cat', 'sat', 'on', 'the', 'mat']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in word_tokenize(my_sent) if re.search(\"\\w\",\tword.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1d68a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([word for word in word_tokenize(my_sent) if re.search(\"\\w\",\tword.lower())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc92127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sent_tokens_no_punctuation = set(word for word in word_tokenize(my_sent) if re.search(\"\\w\",\tword.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5728ec5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The', 'cat', 'mat', 'on', 'sat', 'the'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sent_tokens_no_punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5566ab27",
   "metadata": {},
   "source": [
    "<h6> Formally, 'The' and 'the' are considered different. We should convert all the words to lowercase beforehand, allowing the set to omit duplicate words. </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3ac8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sent_tokens_no_punctuation = set(word for word in word_tokenize(my_sent.lower()) if re.search(\"\\w\",\tword.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "baf9f32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat', 'mat', 'on', 'sat', 'the'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sent_tokens_no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54a31780",
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick_tokens = books.text1.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94b50ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick_tokens_nopunct = [word.lower() for word in moby_dick_tokens if re.search(\"\\w\", word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81748517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moby', 'dick', 'by', 'herman', 'melville']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_dick_tokens_nopunct[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2091328c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218621"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is the number of tokens in Moby Dick?\n",
    "len(moby_dick_tokens_nopunct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70722467",
   "metadata": {},
   "source": [
    "<h6> The type-token ratio is a linguistic and lexical measure used to assess the diversity of vocabulary in a text or language. It helps in understanding how many different words, or types, are used in relation to the total number of words, or tokens, in a given context. </h6>\n",
    "<ul>\n",
    "    <li>Tokens: Tokens represent the total number of words or units in a text, including repeated instances of the same word. \n",
    "    <li>Types: Types represent the unique or distinct words used in a text.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87eec8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07840051962071347"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Moby Dick type-token ratio\n",
    "len(set(moby_dick_tokens_nopunct))/len(moby_dick_tokens_nopunct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfe12a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.129748424801388"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WSJ type-token\tratio\n",
    "wall_street_tokens = books.text7.tokens\n",
    "wall_street_tokens_nopunct = [word.lower() for word in wall_street_tokens if re.search(\"\\w\", word)]\n",
    "len(set(wall_street_tokens_nopunct))/len(wall_street_tokens_nopunct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0cc0a",
   "metadata": {},
   "source": [
    "<h6> A higher type-token ratio indicates greater lexical diversity because it suggests that a wider variety of words is being used. </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a6399c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005607878474620462"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Maximum Likelikhood Estimate (MLE) for the word WHALE\n",
    "moby_dick_tokens_nopunct.count(\"whale\")/len(moby_dick_tokens_nopunct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f292813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wall_street_tokens_nopunct.count(\"whale\")/len(wall_street_tokens_nopunct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42af421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
